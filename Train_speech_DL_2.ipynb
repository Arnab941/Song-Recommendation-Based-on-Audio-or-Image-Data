{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_speech_DL_2.ipynb","provenance":[],"authorship_tag":"ABX9TyPOMhnRRtPxmlG3534hyV9O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tj4NkhxKIKBv","executionInfo":{"status":"ok","timestamp":1631636779143,"user_tz":-330,"elapsed":39317,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"ae3941f6-1e58-4544-ecc3-ef90b07f8e2e"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TessNy85IK7C","executionInfo":{"status":"ok","timestamp":1631636817435,"user_tz":-330,"elapsed":4496,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"8dd2c545-57f7-4c55-8318-71c80a93bf3d"},"source":["!pip install librosa"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n"]}]},{"cell_type":"code","metadata":{"id":"yZ5gypAIIfHD"},"source":["import librosa\n","from librosa import display\n","\n","data, sampling_rate = librosa.load('/content/drive/My Drive/Deep_learning_datasets/Ravdess/Ravdess_Speech/Actor_04/03-02-06-02-02-02-04.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"tFiLP8ZgIl7o","executionInfo":{"status":"ok","timestamp":1631636864217,"user_tz":-330,"elapsed":612,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"1c61e7df-616a-427c-c43e-1c1408d88b03"},"source":["% pylab inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 4))\n","librosa.display.waveplot(data, sr=sampling_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n","`%matplotlib` prevents importing * from pylab and numpy\n","  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PolyCollection at 0x7f18adb7cb50>"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NGUSafVIrZQ","executionInfo":{"status":"ok","timestamp":1631640303777,"user_tz":-330,"elapsed":2084937,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"4eab5775-ade6-4d6b-948e-4bc144e1744c"},"source":["import time\n","import os\n","path = '/content/drive/My Drive/Deep_learning_datasets/Ravdess/Ravdess_Speech/'\n","lst = []\n","\n","start_time = time.time()\n","\n","for subdir, dirs, files in os.walk(path):\n","  for file in files:\n","      try:\n","        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n","        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n","        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n","        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n","        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n","        file = int(file[7:8]) - 1 \n","        arr = mfccs, file\n","        lst.append(arr)\n","      # If the file is not valid, skip it\n","      except ValueError:\n","        continue\n","\n","print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Data loaded. Loading time: 2084.418170452118 seconds ---\n"]}]},{"cell_type":"code","metadata":{"id":"TWAePrPpN2Wx"},"source":["# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n","X, y = zip(*lst)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5V_Fwq7ZbXQ","executionInfo":{"status":"ok","timestamp":1631641267221,"user_tz":-330,"elapsed":1660,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"64487265-93f4-4d4f-9b3a-e787d60eb0ad"},"source":["import numpy as np\n","X = np.asarray(X)\n","y = np.asarray(y)\n","\n","\n","X.shape, y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5272, 40), (5272,))"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ldWcZW7tZd7d"},"source":["# Saving joblib files to not load them again with the loop above\n","\n","import joblib\n","\n","X_name = 'X.joblib'\n","y_name = 'y.joblib'\n","save_dir = '/content/drive/My Drive/Deep_learning_datasets/Ravdess/Project_model_DI'\n","\n","savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n","savedy = joblib.dump(y, os.path.join(save_dir, y_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAj_xHtfZhrc"},"source":["import joblib\n","X = joblib.load('/content/drive/My Drive/Deep_learning_datasets/Ravdess/Project_model_DI/X.joblib')\n","y = joblib.load('/content/drive/My Drive/Deep_learning_datasets/Ravdess/Project_model_DI/y.joblib')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUQPyU_7ZlXt"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16cE5phfZobE"},"source":["from sklearn.tree import DecisionTreeClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlAIEBwXZq2U"},"source":["dtree = DecisionTreeClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGOvo8dSZtaH","executionInfo":{"status":"ok","timestamp":1631641342407,"user_tz":-330,"elapsed":445,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"da9807b4-29fd-4dd6-92ae-ca56de3bd5df"},"source":["dtree.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=None, splitter='best')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"w-d2sxC_Zwnk"},"source":["predictions = dtree.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jUS5gotZzns","executionInfo":{"status":"ok","timestamp":1631641364210,"user_tz":-330,"elapsed":438,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"fb51f61b-389f-4ebe-8e7d-a67cd9021b5e"},"source":["from sklearn.metrics import classification_report,confusion_matrix\n","print(classification_report(y_test,predictions))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.80      0.80       191\n","           1       0.66      0.61      0.63       132\n","           2       0.66      0.64      0.65       246\n","           3       0.63      0.70      0.66       263\n","           4       0.70      0.69      0.69       267\n","           5       0.63      0.69      0.66       253\n","           6       0.67      0.65      0.66       189\n","           7       0.67      0.59      0.63       199\n","\n","    accuracy                           0.67      1740\n","   macro avg       0.68      0.67      0.67      1740\n","weighted avg       0.67      0.67      0.67      1740\n","\n"]}]},{"cell_type":"code","metadata":{"id":"yYdf7n9cZ2Ks"},"source":["import numpy as np\n","x_traincnn = np.expand_dims(X_train, axis=2)\n","x_testcnn = np.expand_dims(X_test, axis=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wDQD2YzZ_58","executionInfo":{"status":"ok","timestamp":1631641413667,"user_tz":-330,"elapsed":420,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"91fe47dd-b79c-468b-9f31-b44d36ed54bf"},"source":["x_traincnn.shape, x_testcnn.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3532, 40, 1), (1740, 40, 1))"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAKPADvCaCPl","executionInfo":{"status":"ok","timestamp":1631641565498,"user_tz":-330,"elapsed":404,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"931c4d9e-d34e-4ddf-e6fd-f05309f76de2"},"source":["import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","# from keras.utils import to_categorical\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Input, Flatten, Dropout, Activation\n","from keras.layers import Conv1D, MaxPooling1D\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","#later\n","from tensorflow.keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Conv1D(64, 5,padding='same',\n","                 input_shape=(40,1)))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.1))\n","model.add(MaxPooling1D(pool_size=(4)))\n","model.add(Conv1D(128, 5,padding='same',))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.1))\n","model.add(MaxPooling1D(pool_size=(4)))\n","model.add(Conv1D(256, 5,padding='same',))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.1))\n","model.add(Flatten())\n","model.add(Dense(8))\n","model.add(Activation('softmax'))\n","# opt = keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=1e-07, decay=0.0)\n","opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=1e-07, decay=0.0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DLIZ0G9aFfE","executionInfo":{"status":"ok","timestamp":1631641579247,"user_tz":-330,"elapsed":435,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"1406447b-1b56-427f-d11b-968754d72e4e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_3 (Conv1D)            (None, 40, 64)            384       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 40, 64)            0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 40, 64)            0         \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 10, 64)            0         \n","_________________________________________________________________\n","conv1d_4 (Conv1D)            (None, 10, 128)           41088     \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 10, 128)           0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 10, 128)           0         \n","_________________________________________________________________\n","max_pooling1d_3 (MaxPooling1 (None, 2, 128)            0         \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, 2, 256)            164096    \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 2, 256)            0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 2, 256)            0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 4104      \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 8)                 0         \n","=================================================================\n","Total params: 209,672\n","Trainable params: 209,672\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"sOGvH-KQaqqj"},"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHRrAqmBauHb"},"source":["checkpoint = ModelCheckpoint('model-{epoch:03d}-{val_accuracy:03f}.h5', verbose=1, monitor='val_accuracy',save_best_only=True, mode='auto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw8W5817azcj","executionInfo":{"status":"ok","timestamp":1631642400717,"user_tz":-330,"elapsed":775474,"user":{"displayName":"arnab nandy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11220873114362016428"}},"outputId":"d3f83a65-126c-401b-e1c4-d0c54e2ee812"},"source":["cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=200, validation_data=(x_testcnn, y_test),callbacks=[checkpoint], verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","221/221 [==============================] - 5s 18ms/step - loss: 4.1176 - accuracy: 0.1806 - val_loss: 2.0181 - val_accuracy: 0.2655\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.26552, saving model to model-001-0.265517.h5\n","Epoch 2/200\n","221/221 [==============================] - 4s 16ms/step - loss: 2.4071 - accuracy: 0.2990 - val_loss: 1.5654 - val_accuracy: 0.4822\n","\n","Epoch 00002: val_accuracy improved from 0.26552 to 0.48218, saving model to model-002-0.482184.h5\n","Epoch 3/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.8630 - accuracy: 0.3862 - val_loss: 1.3784 - val_accuracy: 0.5161\n","\n","Epoch 00003: val_accuracy improved from 0.48218 to 0.51609, saving model to model-003-0.516092.h5\n","Epoch 4/200\n","221/221 [==============================] - 4s 17ms/step - loss: 1.6117 - accuracy: 0.4626 - val_loss: 1.3132 - val_accuracy: 0.5431\n","\n","Epoch 00004: val_accuracy improved from 0.51609 to 0.54310, saving model to model-004-0.543103.h5\n","Epoch 5/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.4364 - accuracy: 0.5176 - val_loss: 1.2165 - val_accuracy: 0.5747\n","\n","Epoch 00005: val_accuracy improved from 0.54310 to 0.57471, saving model to model-005-0.574713.h5\n","Epoch 6/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.3288 - accuracy: 0.5512 - val_loss: 1.1208 - val_accuracy: 0.6017\n","\n","Epoch 00006: val_accuracy improved from 0.57471 to 0.60172, saving model to model-006-0.601724.h5\n","Epoch 7/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.2699 - accuracy: 0.5702 - val_loss: 1.0886 - val_accuracy: 0.6184\n","\n","Epoch 00007: val_accuracy improved from 0.60172 to 0.61839, saving model to model-007-0.618391.h5\n","Epoch 8/200\n","221/221 [==============================] - 4s 17ms/step - loss: 1.2140 - accuracy: 0.5864 - val_loss: 1.0752 - val_accuracy: 0.6241\n","\n","Epoch 00008: val_accuracy improved from 0.61839 to 0.62414, saving model to model-008-0.624138.h5\n","Epoch 9/200\n","221/221 [==============================] - 4s 17ms/step - loss: 1.1471 - accuracy: 0.5954 - val_loss: 1.0291 - val_accuracy: 0.6356\n","\n","Epoch 00009: val_accuracy improved from 0.62414 to 0.63563, saving model to model-009-0.635632.h5\n","Epoch 10/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.1181 - accuracy: 0.6133 - val_loss: 0.9540 - val_accuracy: 0.6598\n","\n","Epoch 00010: val_accuracy improved from 0.63563 to 0.65977, saving model to model-010-0.659770.h5\n","Epoch 11/200\n","221/221 [==============================] - 4s 18ms/step - loss: 1.0673 - accuracy: 0.6283 - val_loss: 0.9205 - val_accuracy: 0.6741\n","\n","Epoch 00011: val_accuracy improved from 0.65977 to 0.67414, saving model to model-011-0.674138.h5\n","Epoch 12/200\n","221/221 [==============================] - 4s 16ms/step - loss: 1.0277 - accuracy: 0.6311 - val_loss: 0.9179 - val_accuracy: 0.6632\n","\n","Epoch 00012: val_accuracy did not improve from 0.67414\n","Epoch 13/200\n","221/221 [==============================] - 4s 17ms/step - loss: 1.0019 - accuracy: 0.6345 - val_loss: 0.9184 - val_accuracy: 0.6586\n","\n","Epoch 00013: val_accuracy did not improve from 0.67414\n","Epoch 14/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.9929 - accuracy: 0.6452 - val_loss: 0.8838 - val_accuracy: 0.6805\n","\n","Epoch 00014: val_accuracy improved from 0.67414 to 0.68046, saving model to model-014-0.680460.h5\n","Epoch 15/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.9509 - accuracy: 0.6535 - val_loss: 0.8754 - val_accuracy: 0.6770\n","\n","Epoch 00015: val_accuracy did not improve from 0.68046\n","Epoch 16/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.9568 - accuracy: 0.6401 - val_loss: 0.8692 - val_accuracy: 0.6839\n","\n","Epoch 00016: val_accuracy improved from 0.68046 to 0.68391, saving model to model-016-0.683908.h5\n","Epoch 17/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.9209 - accuracy: 0.6682 - val_loss: 0.8452 - val_accuracy: 0.6943\n","\n","Epoch 00017: val_accuracy improved from 0.68391 to 0.69425, saving model to model-017-0.694253.h5\n","Epoch 18/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.9135 - accuracy: 0.6651 - val_loss: 0.8249 - val_accuracy: 0.7034\n","\n","Epoch 00018: val_accuracy improved from 0.69425 to 0.70345, saving model to model-018-0.703448.h5\n","Epoch 19/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8773 - accuracy: 0.6758 - val_loss: 0.8360 - val_accuracy: 0.6747\n","\n","Epoch 00019: val_accuracy did not improve from 0.70345\n","Epoch 20/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.8717 - accuracy: 0.6764 - val_loss: 0.7992 - val_accuracy: 0.7161\n","\n","Epoch 00020: val_accuracy improved from 0.70345 to 0.71609, saving model to model-020-0.716092.h5\n","Epoch 21/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8618 - accuracy: 0.6809 - val_loss: 0.7846 - val_accuracy: 0.7195\n","\n","Epoch 00021: val_accuracy improved from 0.71609 to 0.71954, saving model to model-021-0.719540.h5\n","Epoch 22/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8640 - accuracy: 0.6804 - val_loss: 0.7943 - val_accuracy: 0.7138\n","\n","Epoch 00022: val_accuracy did not improve from 0.71954\n","Epoch 23/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8404 - accuracy: 0.6922 - val_loss: 0.7735 - val_accuracy: 0.7201\n","\n","Epoch 00023: val_accuracy improved from 0.71954 to 0.72011, saving model to model-023-0.720115.h5\n","Epoch 24/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8226 - accuracy: 0.6982 - val_loss: 0.7746 - val_accuracy: 0.7029\n","\n","Epoch 00024: val_accuracy did not improve from 0.72011\n","Epoch 25/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.8119 - accuracy: 0.7041 - val_loss: 0.7625 - val_accuracy: 0.7115\n","\n","Epoch 00025: val_accuracy did not improve from 0.72011\n","Epoch 26/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.8189 - accuracy: 0.6934 - val_loss: 0.7591 - val_accuracy: 0.7098\n","\n","Epoch 00026: val_accuracy did not improve from 0.72011\n","Epoch 27/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7983 - accuracy: 0.7047 - val_loss: 0.7540 - val_accuracy: 0.7241\n","\n","Epoch 00027: val_accuracy improved from 0.72011 to 0.72414, saving model to model-027-0.724138.h5\n","Epoch 28/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.7842 - accuracy: 0.7067 - val_loss: 0.7629 - val_accuracy: 0.7155\n","\n","Epoch 00028: val_accuracy did not improve from 0.72414\n","Epoch 29/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.7704 - accuracy: 0.7041 - val_loss: 0.7200 - val_accuracy: 0.7391\n","\n","Epoch 00029: val_accuracy improved from 0.72414 to 0.73908, saving model to model-029-0.739080.h5\n","Epoch 30/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7692 - accuracy: 0.7092 - val_loss: 0.7659 - val_accuracy: 0.7305\n","\n","Epoch 00030: val_accuracy did not improve from 0.73908\n","Epoch 31/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.7629 - accuracy: 0.7146 - val_loss: 0.7250 - val_accuracy: 0.7264\n","\n","Epoch 00031: val_accuracy did not improve from 0.73908\n","Epoch 32/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.7450 - accuracy: 0.7225 - val_loss: 0.6966 - val_accuracy: 0.7511\n","\n","Epoch 00032: val_accuracy improved from 0.73908 to 0.75115, saving model to model-032-0.751149.h5\n","Epoch 33/200\n","221/221 [==============================] - 3s 16ms/step - loss: 0.7594 - accuracy: 0.7166 - val_loss: 0.7124 - val_accuracy: 0.7391\n","\n","Epoch 00033: val_accuracy did not improve from 0.75115\n","Epoch 34/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7524 - accuracy: 0.7172 - val_loss: 0.7019 - val_accuracy: 0.7385\n","\n","Epoch 00034: val_accuracy did not improve from 0.75115\n","Epoch 35/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7246 - accuracy: 0.7276 - val_loss: 0.6970 - val_accuracy: 0.7517\n","\n","Epoch 00035: val_accuracy improved from 0.75115 to 0.75172, saving model to model-035-0.751724.h5\n","Epoch 36/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7244 - accuracy: 0.7276 - val_loss: 0.6826 - val_accuracy: 0.7534\n","\n","Epoch 00036: val_accuracy improved from 0.75172 to 0.75345, saving model to model-036-0.753448.h5\n","Epoch 37/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.7178 - accuracy: 0.7333 - val_loss: 0.6962 - val_accuracy: 0.7310\n","\n","Epoch 00037: val_accuracy did not improve from 0.75345\n","Epoch 38/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.7077 - accuracy: 0.7375 - val_loss: 0.6761 - val_accuracy: 0.7523\n","\n","Epoch 00038: val_accuracy did not improve from 0.75345\n","Epoch 39/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.7064 - accuracy: 0.7395 - val_loss: 0.6787 - val_accuracy: 0.7471\n","\n","Epoch 00039: val_accuracy did not improve from 0.75345\n","Epoch 40/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6929 - accuracy: 0.7384 - val_loss: 0.6812 - val_accuracy: 0.7506\n","\n","Epoch 00040: val_accuracy did not improve from 0.75345\n","Epoch 41/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6928 - accuracy: 0.7392 - val_loss: 0.6650 - val_accuracy: 0.7638\n","\n","Epoch 00041: val_accuracy improved from 0.75345 to 0.76379, saving model to model-041-0.763793.h5\n","Epoch 42/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6827 - accuracy: 0.7441 - val_loss: 0.6623 - val_accuracy: 0.7672\n","\n","Epoch 00042: val_accuracy improved from 0.76379 to 0.76724, saving model to model-042-0.767241.h5\n","Epoch 43/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6815 - accuracy: 0.7458 - val_loss: 0.6617 - val_accuracy: 0.7540\n","\n","Epoch 00043: val_accuracy did not improve from 0.76724\n","Epoch 44/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6797 - accuracy: 0.7514 - val_loss: 0.6575 - val_accuracy: 0.7540\n","\n","Epoch 00044: val_accuracy did not improve from 0.76724\n","Epoch 45/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.6665 - accuracy: 0.7455 - val_loss: 0.6405 - val_accuracy: 0.7741\n","\n","Epoch 00045: val_accuracy improved from 0.76724 to 0.77414, saving model to model-045-0.774138.h5\n","Epoch 46/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6705 - accuracy: 0.7494 - val_loss: 0.6489 - val_accuracy: 0.7667\n","\n","Epoch 00046: val_accuracy did not improve from 0.77414\n","Epoch 47/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6609 - accuracy: 0.7545 - val_loss: 0.6359 - val_accuracy: 0.7741\n","\n","Epoch 00047: val_accuracy did not improve from 0.77414\n","Epoch 48/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6559 - accuracy: 0.7542 - val_loss: 0.6333 - val_accuracy: 0.7793\n","\n","Epoch 00048: val_accuracy improved from 0.77414 to 0.77931, saving model to model-048-0.779310.h5\n","Epoch 49/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.6392 - accuracy: 0.7681 - val_loss: 0.6345 - val_accuracy: 0.7672\n","\n","Epoch 00049: val_accuracy did not improve from 0.77931\n","Epoch 50/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6481 - accuracy: 0.7576 - val_loss: 0.6285 - val_accuracy: 0.7810\n","\n","Epoch 00050: val_accuracy improved from 0.77931 to 0.78103, saving model to model-050-0.781034.h5\n","Epoch 51/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6278 - accuracy: 0.7644 - val_loss: 0.6323 - val_accuracy: 0.7713\n","\n","Epoch 00051: val_accuracy did not improve from 0.78103\n","Epoch 52/200\n","221/221 [==============================] - 3s 16ms/step - loss: 0.6344 - accuracy: 0.7633 - val_loss: 0.6279 - val_accuracy: 0.7667\n","\n","Epoch 00052: val_accuracy did not improve from 0.78103\n","Epoch 53/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.6280 - accuracy: 0.7636 - val_loss: 0.6241 - val_accuracy: 0.7695\n","\n","Epoch 00053: val_accuracy did not improve from 0.78103\n","Epoch 54/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6282 - accuracy: 0.7670 - val_loss: 0.6125 - val_accuracy: 0.7822\n","\n","Epoch 00054: val_accuracy improved from 0.78103 to 0.78218, saving model to model-054-0.782184.h5\n","Epoch 55/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6310 - accuracy: 0.7698 - val_loss: 0.6065 - val_accuracy: 0.7793\n","\n","Epoch 00055: val_accuracy did not improve from 0.78218\n","Epoch 56/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6151 - accuracy: 0.7721 - val_loss: 0.6160 - val_accuracy: 0.7707\n","\n","Epoch 00056: val_accuracy did not improve from 0.78218\n","Epoch 57/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5991 - accuracy: 0.7786 - val_loss: 0.6138 - val_accuracy: 0.7701\n","\n","Epoch 00057: val_accuracy did not improve from 0.78218\n","Epoch 58/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5990 - accuracy: 0.7766 - val_loss: 0.6170 - val_accuracy: 0.7730\n","\n","Epoch 00058: val_accuracy did not improve from 0.78218\n","Epoch 59/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.6052 - accuracy: 0.7715 - val_loss: 0.5987 - val_accuracy: 0.7851\n","\n","Epoch 00059: val_accuracy improved from 0.78218 to 0.78506, saving model to model-059-0.785057.h5\n","Epoch 60/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.6094 - accuracy: 0.7727 - val_loss: 0.6222 - val_accuracy: 0.7753\n","\n","Epoch 00060: val_accuracy did not improve from 0.78506\n","Epoch 61/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5838 - accuracy: 0.7828 - val_loss: 0.6051 - val_accuracy: 0.7701\n","\n","Epoch 00061: val_accuracy did not improve from 0.78506\n","Epoch 62/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5943 - accuracy: 0.7809 - val_loss: 0.5932 - val_accuracy: 0.7805\n","\n","Epoch 00062: val_accuracy did not improve from 0.78506\n","Epoch 63/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5966 - accuracy: 0.7794 - val_loss: 0.5962 - val_accuracy: 0.7874\n","\n","Epoch 00063: val_accuracy improved from 0.78506 to 0.78736, saving model to model-063-0.787356.h5\n","Epoch 64/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5732 - accuracy: 0.7823 - val_loss: 0.6033 - val_accuracy: 0.7724\n","\n","Epoch 00064: val_accuracy did not improve from 0.78736\n","Epoch 65/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5723 - accuracy: 0.7885 - val_loss: 0.5888 - val_accuracy: 0.7897\n","\n","Epoch 00065: val_accuracy improved from 0.78736 to 0.78966, saving model to model-065-0.789655.h5\n","Epoch 66/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5775 - accuracy: 0.7885 - val_loss: 0.6040 - val_accuracy: 0.7799\n","\n","Epoch 00066: val_accuracy did not improve from 0.78966\n","Epoch 67/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5798 - accuracy: 0.7874 - val_loss: 0.5994 - val_accuracy: 0.7753\n","\n","Epoch 00067: val_accuracy did not improve from 0.78966\n","Epoch 68/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5694 - accuracy: 0.7854 - val_loss: 0.5803 - val_accuracy: 0.7908\n","\n","Epoch 00068: val_accuracy improved from 0.78966 to 0.79080, saving model to model-068-0.790805.h5\n","Epoch 69/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5625 - accuracy: 0.7911 - val_loss: 0.5949 - val_accuracy: 0.7828\n","\n","Epoch 00069: val_accuracy did not improve from 0.79080\n","Epoch 70/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5612 - accuracy: 0.7919 - val_loss: 0.5850 - val_accuracy: 0.7805\n","\n","Epoch 00070: val_accuracy did not improve from 0.79080\n","Epoch 71/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5551 - accuracy: 0.7913 - val_loss: 0.5766 - val_accuracy: 0.7816\n","\n","Epoch 00071: val_accuracy did not improve from 0.79080\n","Epoch 72/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5509 - accuracy: 0.7953 - val_loss: 0.5735 - val_accuracy: 0.7943\n","\n","Epoch 00072: val_accuracy improved from 0.79080 to 0.79425, saving model to model-072-0.794253.h5\n","Epoch 73/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.5470 - accuracy: 0.7964 - val_loss: 0.5751 - val_accuracy: 0.7874\n","\n","Epoch 00073: val_accuracy did not improve from 0.79425\n","Epoch 74/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5406 - accuracy: 0.8021 - val_loss: 0.5845 - val_accuracy: 0.7805\n","\n","Epoch 00074: val_accuracy did not improve from 0.79425\n","Epoch 75/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5523 - accuracy: 0.7928 - val_loss: 0.5735 - val_accuracy: 0.7902\n","\n","Epoch 00075: val_accuracy did not improve from 0.79425\n","Epoch 76/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.5501 - accuracy: 0.8004 - val_loss: 0.5802 - val_accuracy: 0.7822\n","\n","Epoch 00076: val_accuracy did not improve from 0.79425\n","Epoch 77/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5431 - accuracy: 0.8018 - val_loss: 0.5797 - val_accuracy: 0.7902\n","\n","Epoch 00077: val_accuracy did not improve from 0.79425\n","Epoch 78/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5293 - accuracy: 0.8032 - val_loss: 0.5613 - val_accuracy: 0.7977\n","\n","Epoch 00078: val_accuracy improved from 0.79425 to 0.79770, saving model to model-078-0.797701.h5\n","Epoch 79/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5243 - accuracy: 0.8055 - val_loss: 0.5715 - val_accuracy: 0.7937\n","\n","Epoch 00079: val_accuracy did not improve from 0.79770\n","Epoch 80/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5282 - accuracy: 0.8001 - val_loss: 0.5722 - val_accuracy: 0.7897\n","\n","Epoch 00080: val_accuracy did not improve from 0.79770\n","Epoch 81/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5152 - accuracy: 0.8063 - val_loss: 0.5681 - val_accuracy: 0.7937\n","\n","Epoch 00081: val_accuracy did not improve from 0.79770\n","Epoch 82/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5210 - accuracy: 0.8044 - val_loss: 0.5529 - val_accuracy: 0.8000\n","\n","Epoch 00082: val_accuracy improved from 0.79770 to 0.80000, saving model to model-082-0.800000.h5\n","Epoch 83/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5099 - accuracy: 0.8151 - val_loss: 0.5743 - val_accuracy: 0.7776\n","\n","Epoch 00083: val_accuracy did not improve from 0.80000\n","Epoch 84/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5153 - accuracy: 0.8095 - val_loss: 0.5729 - val_accuracy: 0.7874\n","\n","Epoch 00084: val_accuracy did not improve from 0.80000\n","Epoch 85/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5319 - accuracy: 0.7993 - val_loss: 0.5549 - val_accuracy: 0.7954\n","\n","Epoch 00085: val_accuracy did not improve from 0.80000\n","Epoch 86/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5137 - accuracy: 0.8032 - val_loss: 0.5507 - val_accuracy: 0.8063\n","\n","Epoch 00086: val_accuracy improved from 0.80000 to 0.80632, saving model to model-086-0.806322.h5\n","Epoch 87/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.5106 - accuracy: 0.8063 - val_loss: 0.5633 - val_accuracy: 0.7856\n","\n","Epoch 00087: val_accuracy did not improve from 0.80632\n","Epoch 88/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5026 - accuracy: 0.8194 - val_loss: 0.5435 - val_accuracy: 0.8006\n","\n","Epoch 00088: val_accuracy did not improve from 0.80632\n","Epoch 89/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.5003 - accuracy: 0.8157 - val_loss: 0.5393 - val_accuracy: 0.7983\n","\n","Epoch 00089: val_accuracy did not improve from 0.80632\n","Epoch 90/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4983 - accuracy: 0.8126 - val_loss: 0.5488 - val_accuracy: 0.7948\n","\n","Epoch 00090: val_accuracy did not improve from 0.80632\n","Epoch 91/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4988 - accuracy: 0.8143 - val_loss: 0.5388 - val_accuracy: 0.7977\n","\n","Epoch 00091: val_accuracy did not improve from 0.80632\n","Epoch 92/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4972 - accuracy: 0.8188 - val_loss: 0.5402 - val_accuracy: 0.8040\n","\n","Epoch 00092: val_accuracy did not improve from 0.80632\n","Epoch 93/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4950 - accuracy: 0.8160 - val_loss: 0.5393 - val_accuracy: 0.8057\n","\n","Epoch 00093: val_accuracy did not improve from 0.80632\n","Epoch 94/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.4970 - accuracy: 0.8182 - val_loss: 0.5352 - val_accuracy: 0.8075\n","\n","Epoch 00094: val_accuracy improved from 0.80632 to 0.80747, saving model to model-094-0.807471.h5\n","Epoch 95/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4877 - accuracy: 0.8168 - val_loss: 0.5313 - val_accuracy: 0.8029\n","\n","Epoch 00095: val_accuracy did not improve from 0.80747\n","Epoch 96/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.4869 - accuracy: 0.8233 - val_loss: 0.5276 - val_accuracy: 0.8069\n","\n","Epoch 00096: val_accuracy did not improve from 0.80747\n","Epoch 97/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4832 - accuracy: 0.8180 - val_loss: 0.5341 - val_accuracy: 0.7989\n","\n","Epoch 00097: val_accuracy did not improve from 0.80747\n","Epoch 98/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4799 - accuracy: 0.8208 - val_loss: 0.5438 - val_accuracy: 0.7994\n","\n","Epoch 00098: val_accuracy did not improve from 0.80747\n","Epoch 99/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4822 - accuracy: 0.8168 - val_loss: 0.5356 - val_accuracy: 0.8006\n","\n","Epoch 00099: val_accuracy did not improve from 0.80747\n","Epoch 100/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4674 - accuracy: 0.8298 - val_loss: 0.5385 - val_accuracy: 0.7983\n","\n","Epoch 00100: val_accuracy did not improve from 0.80747\n","Epoch 101/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4707 - accuracy: 0.8247 - val_loss: 0.5326 - val_accuracy: 0.8046\n","\n","Epoch 00101: val_accuracy did not improve from 0.80747\n","Epoch 102/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4589 - accuracy: 0.8304 - val_loss: 0.5234 - val_accuracy: 0.8126\n","\n","Epoch 00102: val_accuracy improved from 0.80747 to 0.81264, saving model to model-102-0.812644.h5\n","Epoch 103/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4691 - accuracy: 0.8213 - val_loss: 0.5237 - val_accuracy: 0.8109\n","\n","Epoch 00103: val_accuracy did not improve from 0.81264\n","Epoch 104/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4641 - accuracy: 0.8315 - val_loss: 0.5228 - val_accuracy: 0.8046\n","\n","Epoch 00104: val_accuracy did not improve from 0.81264\n","Epoch 105/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4670 - accuracy: 0.8262 - val_loss: 0.5253 - val_accuracy: 0.8115\n","\n","Epoch 00105: val_accuracy did not improve from 0.81264\n","Epoch 106/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4628 - accuracy: 0.8281 - val_loss: 0.5249 - val_accuracy: 0.8040\n","\n","Epoch 00106: val_accuracy did not improve from 0.81264\n","Epoch 107/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4582 - accuracy: 0.8341 - val_loss: 0.5236 - val_accuracy: 0.8109\n","\n","Epoch 00107: val_accuracy did not improve from 0.81264\n","Epoch 108/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4542 - accuracy: 0.8335 - val_loss: 0.5135 - val_accuracy: 0.8172\n","\n","Epoch 00108: val_accuracy improved from 0.81264 to 0.81724, saving model to model-108-0.817241.h5\n","Epoch 109/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4598 - accuracy: 0.8262 - val_loss: 0.5291 - val_accuracy: 0.8069\n","\n","Epoch 00109: val_accuracy did not improve from 0.81724\n","Epoch 110/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4509 - accuracy: 0.8310 - val_loss: 0.5197 - val_accuracy: 0.8144\n","\n","Epoch 00110: val_accuracy did not improve from 0.81724\n","Epoch 111/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.4474 - accuracy: 0.8349 - val_loss: 0.5420 - val_accuracy: 0.8011\n","\n","Epoch 00111: val_accuracy did not improve from 0.81724\n","Epoch 112/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4430 - accuracy: 0.8352 - val_loss: 0.5469 - val_accuracy: 0.7983\n","\n","Epoch 00112: val_accuracy did not improve from 0.81724\n","Epoch 113/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4507 - accuracy: 0.8256 - val_loss: 0.5216 - val_accuracy: 0.8092\n","\n","Epoch 00113: val_accuracy did not improve from 0.81724\n","Epoch 114/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4390 - accuracy: 0.8375 - val_loss: 0.5255 - val_accuracy: 0.8138\n","\n","Epoch 00114: val_accuracy did not improve from 0.81724\n","Epoch 115/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4441 - accuracy: 0.8307 - val_loss: 0.5148 - val_accuracy: 0.8138\n","\n","Epoch 00115: val_accuracy did not improve from 0.81724\n","Epoch 116/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4386 - accuracy: 0.8355 - val_loss: 0.5210 - val_accuracy: 0.8138\n","\n","Epoch 00116: val_accuracy did not improve from 0.81724\n","Epoch 117/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.4378 - accuracy: 0.8366 - val_loss: 0.5187 - val_accuracy: 0.8115\n","\n","Epoch 00117: val_accuracy did not improve from 0.81724\n","Epoch 118/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.4422 - accuracy: 0.8375 - val_loss: 0.5049 - val_accuracy: 0.8241\n","\n","Epoch 00118: val_accuracy improved from 0.81724 to 0.82414, saving model to model-118-0.824138.h5\n","Epoch 119/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4205 - accuracy: 0.8414 - val_loss: 0.5050 - val_accuracy: 0.8161\n","\n","Epoch 00119: val_accuracy did not improve from 0.82414\n","Epoch 120/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4314 - accuracy: 0.8369 - val_loss: 0.5191 - val_accuracy: 0.8115\n","\n","Epoch 00120: val_accuracy did not improve from 0.82414\n","Epoch 121/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4281 - accuracy: 0.8375 - val_loss: 0.5061 - val_accuracy: 0.8155\n","\n","Epoch 00121: val_accuracy did not improve from 0.82414\n","Epoch 122/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.4164 - accuracy: 0.8446 - val_loss: 0.5177 - val_accuracy: 0.8103\n","\n","Epoch 00122: val_accuracy did not improve from 0.82414\n","Epoch 123/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4197 - accuracy: 0.8440 - val_loss: 0.5209 - val_accuracy: 0.8098\n","\n","Epoch 00123: val_accuracy did not improve from 0.82414\n","Epoch 124/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4227 - accuracy: 0.8400 - val_loss: 0.5107 - val_accuracy: 0.8144\n","\n","Epoch 00124: val_accuracy did not improve from 0.82414\n","Epoch 125/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4296 - accuracy: 0.8463 - val_loss: 0.5004 - val_accuracy: 0.8213\n","\n","Epoch 00125: val_accuracy did not improve from 0.82414\n","Epoch 126/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4180 - accuracy: 0.8454 - val_loss: 0.5142 - val_accuracy: 0.8121\n","\n","Epoch 00126: val_accuracy did not improve from 0.82414\n","Epoch 127/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4153 - accuracy: 0.8474 - val_loss: 0.4936 - val_accuracy: 0.8224\n","\n","Epoch 00127: val_accuracy did not improve from 0.82414\n","Epoch 128/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.4030 - accuracy: 0.8480 - val_loss: 0.5154 - val_accuracy: 0.8126\n","\n","Epoch 00128: val_accuracy did not improve from 0.82414\n","Epoch 129/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4117 - accuracy: 0.8514 - val_loss: 0.5049 - val_accuracy: 0.8161\n","\n","Epoch 00129: val_accuracy did not improve from 0.82414\n","Epoch 130/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4157 - accuracy: 0.8457 - val_loss: 0.5070 - val_accuracy: 0.8115\n","\n","Epoch 00130: val_accuracy did not improve from 0.82414\n","Epoch 131/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4096 - accuracy: 0.8471 - val_loss: 0.5220 - val_accuracy: 0.8075\n","\n","Epoch 00131: val_accuracy did not improve from 0.82414\n","Epoch 132/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4093 - accuracy: 0.8502 - val_loss: 0.5157 - val_accuracy: 0.8109\n","\n","Epoch 00132: val_accuracy did not improve from 0.82414\n","Epoch 133/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.4161 - accuracy: 0.8451 - val_loss: 0.5079 - val_accuracy: 0.8172\n","\n","Epoch 00133: val_accuracy did not improve from 0.82414\n","Epoch 134/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.3934 - accuracy: 0.8528 - val_loss: 0.5095 - val_accuracy: 0.8121\n","\n","Epoch 00134: val_accuracy did not improve from 0.82414\n","Epoch 135/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.4045 - accuracy: 0.8446 - val_loss: 0.5002 - val_accuracy: 0.8213\n","\n","Epoch 00135: val_accuracy did not improve from 0.82414\n","Epoch 136/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3987 - accuracy: 0.8528 - val_loss: 0.5038 - val_accuracy: 0.8144\n","\n","Epoch 00136: val_accuracy did not improve from 0.82414\n","Epoch 137/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3934 - accuracy: 0.8553 - val_loss: 0.4943 - val_accuracy: 0.8126\n","\n","Epoch 00137: val_accuracy did not improve from 0.82414\n","Epoch 138/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3865 - accuracy: 0.8539 - val_loss: 0.4948 - val_accuracy: 0.8213\n","\n","Epoch 00138: val_accuracy did not improve from 0.82414\n","Epoch 139/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3949 - accuracy: 0.8505 - val_loss: 0.4956 - val_accuracy: 0.8270\n","\n","Epoch 00139: val_accuracy improved from 0.82414 to 0.82701, saving model to model-139-0.827011.h5\n","Epoch 140/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3901 - accuracy: 0.8491 - val_loss: 0.4959 - val_accuracy: 0.8195\n","\n","Epoch 00140: val_accuracy did not improve from 0.82701\n","Epoch 141/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3872 - accuracy: 0.8582 - val_loss: 0.5021 - val_accuracy: 0.8201\n","\n","Epoch 00141: val_accuracy did not improve from 0.82701\n","Epoch 142/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3844 - accuracy: 0.8542 - val_loss: 0.4938 - val_accuracy: 0.8218\n","\n","Epoch 00142: val_accuracy did not improve from 0.82701\n","Epoch 143/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3853 - accuracy: 0.8607 - val_loss: 0.4776 - val_accuracy: 0.8287\n","\n","Epoch 00143: val_accuracy improved from 0.82701 to 0.82874, saving model to model-143-0.828736.h5\n","Epoch 144/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3735 - accuracy: 0.8644 - val_loss: 0.4988 - val_accuracy: 0.8178\n","\n","Epoch 00144: val_accuracy did not improve from 0.82874\n","Epoch 145/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3791 - accuracy: 0.8596 - val_loss: 0.5001 - val_accuracy: 0.8172\n","\n","Epoch 00145: val_accuracy did not improve from 0.82874\n","Epoch 146/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.3747 - accuracy: 0.8633 - val_loss: 0.4962 - val_accuracy: 0.8287\n","\n","Epoch 00146: val_accuracy did not improve from 0.82874\n","Epoch 147/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3786 - accuracy: 0.8624 - val_loss: 0.4962 - val_accuracy: 0.8172\n","\n","Epoch 00147: val_accuracy did not improve from 0.82874\n","Epoch 148/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3754 - accuracy: 0.8570 - val_loss: 0.4838 - val_accuracy: 0.8247\n","\n","Epoch 00148: val_accuracy did not improve from 0.82874\n","Epoch 149/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3771 - accuracy: 0.8582 - val_loss: 0.5030 - val_accuracy: 0.8172\n","\n","Epoch 00149: val_accuracy did not improve from 0.82874\n","Epoch 150/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3857 - accuracy: 0.8584 - val_loss: 0.4839 - val_accuracy: 0.8247\n","\n","Epoch 00150: val_accuracy did not improve from 0.82874\n","Epoch 151/200\n","221/221 [==============================] - 4s 16ms/step - loss: 0.3780 - accuracy: 0.8582 - val_loss: 0.4915 - val_accuracy: 0.8213\n","\n","Epoch 00151: val_accuracy did not improve from 0.82874\n","Epoch 152/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3608 - accuracy: 0.8658 - val_loss: 0.4799 - val_accuracy: 0.8253\n","\n","Epoch 00152: val_accuracy did not improve from 0.82874\n","Epoch 153/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3632 - accuracy: 0.8669 - val_loss: 0.4834 - val_accuracy: 0.8236\n","\n","Epoch 00153: val_accuracy did not improve from 0.82874\n","Epoch 154/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3664 - accuracy: 0.8689 - val_loss: 0.4857 - val_accuracy: 0.8253\n","\n","Epoch 00154: val_accuracy did not improve from 0.82874\n","Epoch 155/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3709 - accuracy: 0.8599 - val_loss: 0.4782 - val_accuracy: 0.8299\n","\n","Epoch 00155: val_accuracy improved from 0.82874 to 0.82989, saving model to model-155-0.829885.h5\n","Epoch 156/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3650 - accuracy: 0.8649 - val_loss: 0.4869 - val_accuracy: 0.8207\n","\n","Epoch 00156: val_accuracy did not improve from 0.82989\n","Epoch 157/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3606 - accuracy: 0.8666 - val_loss: 0.4763 - val_accuracy: 0.8299\n","\n","Epoch 00157: val_accuracy did not improve from 0.82989\n","Epoch 158/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3521 - accuracy: 0.8732 - val_loss: 0.4849 - val_accuracy: 0.8213\n","\n","Epoch 00158: val_accuracy did not improve from 0.82989\n","Epoch 159/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3646 - accuracy: 0.8613 - val_loss: 0.4763 - val_accuracy: 0.8299\n","\n","Epoch 00159: val_accuracy did not improve from 0.82989\n","Epoch 160/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3549 - accuracy: 0.8635 - val_loss: 0.4943 - val_accuracy: 0.8236\n","\n","Epoch 00160: val_accuracy did not improve from 0.82989\n","Epoch 161/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3516 - accuracy: 0.8706 - val_loss: 0.4832 - val_accuracy: 0.8270\n","\n","Epoch 00161: val_accuracy did not improve from 0.82989\n","Epoch 162/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3552 - accuracy: 0.8649 - val_loss: 0.4797 - val_accuracy: 0.8264\n","\n","Epoch 00162: val_accuracy did not improve from 0.82989\n","Epoch 163/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3473 - accuracy: 0.8647 - val_loss: 0.4874 - val_accuracy: 0.8178\n","\n","Epoch 00163: val_accuracy did not improve from 0.82989\n","Epoch 164/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3483 - accuracy: 0.8700 - val_loss: 0.4729 - val_accuracy: 0.8305\n","\n","Epoch 00164: val_accuracy improved from 0.82989 to 0.83046, saving model to model-164-0.830460.h5\n","Epoch 165/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3467 - accuracy: 0.8675 - val_loss: 0.4768 - val_accuracy: 0.8270\n","\n","Epoch 00165: val_accuracy did not improve from 0.83046\n","Epoch 166/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3605 - accuracy: 0.8621 - val_loss: 0.4804 - val_accuracy: 0.8276\n","\n","Epoch 00166: val_accuracy did not improve from 0.83046\n","Epoch 167/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3489 - accuracy: 0.8678 - val_loss: 0.4808 - val_accuracy: 0.8236\n","\n","Epoch 00167: val_accuracy did not improve from 0.83046\n","Epoch 168/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3457 - accuracy: 0.8746 - val_loss: 0.4682 - val_accuracy: 0.8322\n","\n","Epoch 00168: val_accuracy improved from 0.83046 to 0.83218, saving model to model-168-0.832184.h5\n","Epoch 169/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3457 - accuracy: 0.8686 - val_loss: 0.4696 - val_accuracy: 0.8328\n","\n","Epoch 00169: val_accuracy improved from 0.83218 to 0.83276, saving model to model-169-0.832759.h5\n","Epoch 170/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3308 - accuracy: 0.8766 - val_loss: 0.4692 - val_accuracy: 0.8356\n","\n","Epoch 00170: val_accuracy improved from 0.83276 to 0.83563, saving model to model-170-0.835632.h5\n","Epoch 171/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3438 - accuracy: 0.8732 - val_loss: 0.4884 - val_accuracy: 0.8264\n","\n","Epoch 00171: val_accuracy did not improve from 0.83563\n","Epoch 172/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3329 - accuracy: 0.8774 - val_loss: 0.4633 - val_accuracy: 0.8333\n","\n","Epoch 00172: val_accuracy did not improve from 0.83563\n","Epoch 173/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3418 - accuracy: 0.8746 - val_loss: 0.4845 - val_accuracy: 0.8282\n","\n","Epoch 00173: val_accuracy did not improve from 0.83563\n","Epoch 174/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3300 - accuracy: 0.8777 - val_loss: 0.4706 - val_accuracy: 0.8356\n","\n","Epoch 00174: val_accuracy did not improve from 0.83563\n","Epoch 175/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3237 - accuracy: 0.8819 - val_loss: 0.4629 - val_accuracy: 0.8379\n","\n","Epoch 00175: val_accuracy improved from 0.83563 to 0.83793, saving model to model-175-0.837931.h5\n","Epoch 176/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3365 - accuracy: 0.8749 - val_loss: 0.4674 - val_accuracy: 0.8333\n","\n","Epoch 00176: val_accuracy did not improve from 0.83793\n","Epoch 177/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3276 - accuracy: 0.8808 - val_loss: 0.4698 - val_accuracy: 0.8379\n","\n","Epoch 00177: val_accuracy did not improve from 0.83793\n","Epoch 178/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3321 - accuracy: 0.8715 - val_loss: 0.4727 - val_accuracy: 0.8282\n","\n","Epoch 00178: val_accuracy did not improve from 0.83793\n","Epoch 179/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3249 - accuracy: 0.8757 - val_loss: 0.4752 - val_accuracy: 0.8322\n","\n","Epoch 00179: val_accuracy did not improve from 0.83793\n","Epoch 180/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3188 - accuracy: 0.8870 - val_loss: 0.4891 - val_accuracy: 0.8264\n","\n","Epoch 00180: val_accuracy did not improve from 0.83793\n","Epoch 181/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3277 - accuracy: 0.8797 - val_loss: 0.4805 - val_accuracy: 0.8339\n","\n","Epoch 00181: val_accuracy did not improve from 0.83793\n","Epoch 182/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3103 - accuracy: 0.8930 - val_loss: 0.4540 - val_accuracy: 0.8437\n","\n","Epoch 00182: val_accuracy improved from 0.83793 to 0.84368, saving model to model-182-0.843678.h5\n","Epoch 183/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3209 - accuracy: 0.8808 - val_loss: 0.4640 - val_accuracy: 0.8351\n","\n","Epoch 00183: val_accuracy did not improve from 0.84368\n","Epoch 184/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3105 - accuracy: 0.8845 - val_loss: 0.4620 - val_accuracy: 0.8299\n","\n","Epoch 00184: val_accuracy did not improve from 0.84368\n","Epoch 185/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3170 - accuracy: 0.8828 - val_loss: 0.4535 - val_accuracy: 0.8356\n","\n","Epoch 00185: val_accuracy did not improve from 0.84368\n","Epoch 186/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3126 - accuracy: 0.8848 - val_loss: 0.4576 - val_accuracy: 0.8362\n","\n","Epoch 00186: val_accuracy did not improve from 0.84368\n","Epoch 187/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3097 - accuracy: 0.8890 - val_loss: 0.4737 - val_accuracy: 0.8213\n","\n","Epoch 00187: val_accuracy did not improve from 0.84368\n","Epoch 188/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3199 - accuracy: 0.8814 - val_loss: 0.4702 - val_accuracy: 0.8270\n","\n","Epoch 00188: val_accuracy did not improve from 0.84368\n","Epoch 189/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3063 - accuracy: 0.8859 - val_loss: 0.4575 - val_accuracy: 0.8397\n","\n","Epoch 00189: val_accuracy did not improve from 0.84368\n","Epoch 190/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3104 - accuracy: 0.8924 - val_loss: 0.4574 - val_accuracy: 0.8356\n","\n","Epoch 00190: val_accuracy did not improve from 0.84368\n","Epoch 191/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.2982 - accuracy: 0.8896 - val_loss: 0.4742 - val_accuracy: 0.8374\n","\n","Epoch 00191: val_accuracy did not improve from 0.84368\n","Epoch 192/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3120 - accuracy: 0.8879 - val_loss: 0.4668 - val_accuracy: 0.8362\n","\n","Epoch 00192: val_accuracy did not improve from 0.84368\n","Epoch 193/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.3101 - accuracy: 0.8848 - val_loss: 0.4559 - val_accuracy: 0.8368\n","\n","Epoch 00193: val_accuracy did not improve from 0.84368\n","Epoch 194/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3064 - accuracy: 0.8825 - val_loss: 0.4560 - val_accuracy: 0.8328\n","\n","Epoch 00194: val_accuracy did not improve from 0.84368\n","Epoch 195/200\n","221/221 [==============================] - 4s 17ms/step - loss: 0.2929 - accuracy: 0.8981 - val_loss: 0.4733 - val_accuracy: 0.8282\n","\n","Epoch 00195: val_accuracy did not improve from 0.84368\n","Epoch 196/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.3056 - accuracy: 0.8890 - val_loss: 0.4647 - val_accuracy: 0.8368\n","\n","Epoch 00196: val_accuracy did not improve from 0.84368\n","Epoch 197/200\n","221/221 [==============================] - 4s 20ms/step - loss: 0.2991 - accuracy: 0.8887 - val_loss: 0.4510 - val_accuracy: 0.8368\n","\n","Epoch 00197: val_accuracy did not improve from 0.84368\n","Epoch 198/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.2983 - accuracy: 0.8924 - val_loss: 0.4723 - val_accuracy: 0.8328\n","\n","Epoch 00198: val_accuracy did not improve from 0.84368\n","Epoch 199/200\n","221/221 [==============================] - 4s 19ms/step - loss: 0.2882 - accuracy: 0.8995 - val_loss: 0.4779 - val_accuracy: 0.8241\n","\n","Epoch 00199: val_accuracy did not improve from 0.84368\n","Epoch 200/200\n","221/221 [==============================] - 4s 18ms/step - loss: 0.3102 - accuracy: 0.8802 - val_loss: 0.4529 - val_accuracy: 0.8368\n","\n","Epoch 00200: val_accuracy did not improve from 0.84368\n"]}]},{"cell_type":"code","metadata":{"id":"61NozIiCa2AU"},"source":[""],"execution_count":null,"outputs":[]}]}